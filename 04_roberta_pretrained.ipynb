{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoBERTa Classifier with target LM pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will train a RoBERTa classifier for the proxy task using the pretrained target language model for initialization.  The language model is trained in 04_roberta_lm.ipynb.\n",
    "\n",
    "This notebook is adapted from [this](https://towardsdatascience.com/fastai-with-transformers-bert-roberta-xlnet-xlm-distilbert-4f41ee18ecb2) blog post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from transformers import RobertaForSequenceClassification, RobertaConfig\n",
    "import eval_models\n",
    "from train_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "import transformers\n",
    "import tokenizers\n",
    "print('fastai version :', fastai.__version__)\n",
    "print('transformers version :', transformers.__version__)\n",
    "print('tokenizers version :', tokenizers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep databunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "seed = 42\n",
    "tok_model_dir = '/home/dyang/InstrumentID/tokenizer/roberta_tok/shift0'\n",
    "max_seq_len = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_tok = CustomTokenizer(TransformersBaseTokenizer, tok_model_dir, max_seq_len)\n",
    "transformer_base_tokenizer = TransformersBaseTokenizer(tok_model_dir, max_seq_len)\n",
    "transformer_vocab =  TransformersVocab(tokenizer = transformer_base_tokenizer._pretrained_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_idx = transformer_base_tokenizer._pretrained_tokenizer.token_to_id('<pad>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bpe_path = Path('/home/dyang/InstrumentID/train_data')\n",
    "train_df = pd.read_csv(bpe_path/'train_df-frag64.char.csv')\n",
    "valid_df = pd.read_csv(bpe_path/'valid_df-frag64.char.csv')\n",
    "test_df = pd.read_csv(bpe_path/'test_df-frag64.char.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas = TextDataBunch.from_df(bpe_path, train_df, valid_df, tokenizer=cust_tok, vocab=transformer_vocab,\n",
    "                                  include_bos=False, include_eos=False, pad_first=False, pad_idx=pad_idx, \n",
    "                                  bs=bs, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, config_class = RobertaForSequenceClassification, RobertaConfig\n",
    "model_path = '/home/dyang/.fastai/data/bscore_lm/bpe_data/models/roberta_train-target_lm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_class.from_pretrained(model_path)\n",
    "config.num_labels = data_clas.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = model_class.from_pretrained(model_path, config = config)\n",
    "custom_transformer_model = RobertaModelWrapper(transformer_model, pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.destroy()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner(data_clas, custom_transformer_model, metrics=[accuracy, FBeta(average='macro', beta=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_layers = [learner.model.transformer.roberta.embeddings,\n",
    "              learner.model.transformer.roberta.encoder.layer[0],\n",
    "              learner.model.transformer.roberta.encoder.layer[1],\n",
    "              learner.model.transformer.roberta.encoder.layer[2],\n",
    "              learner.model.transformer.roberta.encoder.layer[3],\n",
    "              learner.model.transformer.roberta.encoder.layer[4],\n",
    "              learner.model.transformer.roberta.encoder.layer[5],\n",
    "              learner.model.transformer.roberta.pooler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learner.split(list_layers)\n",
    "print(learner.layer_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learner.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = 3e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learner.fit_one_cycle(2, lr, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learner.freeze_to(-1)\n",
    "learner.fit_one_cycle(2, 3e-6, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learner.freeze_to(-2)\n",
    "learner.fit_one_cycle(2, slice(lr/(2.6**4),lr), moms=(0.8, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learner.freeze_to(-3)\n",
    "learner.fit_one_cycle(2, slice(lr/2/(2.6**4),lr/2), moms=(0.8, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('roberta_unlabeled-frag64-shift3')\n",
    "#learner.load('final_models/roberta_train-target_clas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on the proxy task -- classifying fixed-length chunks of bootleg score features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas_test = TextDataBunch.from_df(bpe_path, train_df, test_df, tokenizer=cust_tok, vocab=transformer_vocab,\n",
    "                                  include_bos=False, include_eos=False, pad_first=False, pad_idx=pad_idx, \n",
    "                                  bs=bs, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.validate(data_clas_test.valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on the original task -- classifying pages of sheet music.  We can evaluate our models in two ways:\n",
    "- applying the model to a variable length sequence\n",
    "- applying the model to multiple fixed-length windows and averaging the predictions\n",
    "\n",
    "First we evaluate the model on variable length inputs.  Report results with and without applying priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fullpage_df = pd.read_csv(bpe_path/'train_df.fullpage.char.csv')\n",
    "valid_fullpage_df = pd.read_csv(bpe_path/'valid_df.fullpage.char.csv')\n",
    "test_fullpage_df = pd.read_csv(bpe_path/'test_df.fullpage.char.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas_test = TextDataBunch.from_df(bpe_path, train_fullpage_df, valid_fullpage_df, test_fullpage_df,\n",
    "                                       tokenizer=cust_tok, vocab=transformer_vocab, include_bos=False, \n",
    "                                       include_eos=False, pad_first=False, pad_idx=pad_idx, bs=bs, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(acc, acc_with_prior), (f1, f1_with_prior), prob, gt = eval_models.calcAccuracy_fullpage1(learner, bpe_path, train_fullpage_df, valid_fullpage_df, test_fullpage_df, databunch=data_clas_test)\n",
    "(acc, acc_with_prior), (f1, f1_with_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob.shape, gt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we evaluate the model by considering multiple fixed-length windows and averaging the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ensemble_df = pd.read_csv(bpe_path/'test.ensemble64.char.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas_test = TextDataBunch.from_df(bpe_path, train_fullpage_df, valid_fullpage_df, test_ensemble_df,\n",
    "                                       text_cols = 'text', label_cols = 'label', tokenizer=cust_tok, \n",
    "                                       vocab=transformer_vocab, include_bos=False, include_eos=False, \n",
    "                                       pad_first=False, pad_idx=pad_idx, bs=bs, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(acc, acc_with_prior), (f1, f1_with_prior) = eval_models.calcAccuracy_fullpage1(learner, bpe_path, train_fullpage_df, valid_fullpage_df, test_ensemble_df, databunch=data_clas_test, ensembled=True)\n",
    "(acc, acc_with_prior), (f1, f1_with_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix(figsize=(12,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = learner.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertLineToCharSeq(line):\n",
    "    ints = [int(p) for p in line.split()]\n",
    "    result = ' '.join([int2charseq(i) for i in ints])\n",
    "    return result\n",
    "def int2charseq(int64):\n",
    "    chars = ''\n",
    "    for i in range(8):\n",
    "        numshift = i * 8\n",
    "        charidx = (int64 >> numshift) & 255\n",
    "        chars += chr(19968 + charidx) # 19968 ensures that all chars are chinese characters (not newline, space, etc)\n",
    "    result = ''.join(chars)\n",
    "    #print(int64,result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for fname in os.listdir(\"/home/dyang/InstrumentID/bootleg_data-v1/labeled/cello/\"):\n",
    "    name = os.path.join(\"/home/dyang/InstrumentID/bootleg_data-v1/labeled/cello/\",fname)    \n",
    "    with open(name,'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        for idx,page in enumerate(data):\n",
    "            pred_string = \"\"\n",
    "            for count,i in enumerate(page):\n",
    "                pred_string+=str(i)+ ' '\n",
    "                if count == 63:\n",
    "                    break\n",
    "            i1 = convertLineToCharSeq(pred_string)\n",
    "            pred_string.strip()\n",
    "            print(str(learner.predict(i1)[0]),learner.predict(i1))\n",
    "            if str(learner.predict(i1)[0]) == \"cello\":\n",
    "                #print(fname,idx+1)\n",
    "                #print(learner.predict(i1)[2])\n",
    "                continue\n",
    "            else:\n",
    "                print(fname,idx+1)\n",
    "                print(learner.predict(i1)[2])\n",
    "                #print(fname,idx+1)\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = learner.show_results(data_clas_test.valid_dl, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_clas.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.iloc[0]['Fragment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertLineToCharSeq(line):\n",
    "    ints = [int(p) for p in line.split()]\n",
    "    result = ' '.join([int2charseq(i) for i in ints])\n",
    "    return result\n",
    "def int2charseq(int64):\n",
    "    chars = ''\n",
    "    for i in range(8):\n",
    "        numshift = i * 8\n",
    "        charidx = (int64 >> numshift) & 255\n",
    "        chars += chr(19968 + charidx) # 19968 ensures that all chars are chinese characters (not newline, space, etc)\n",
    "    result = ''.join(chars)\n",
    "    #print(int64,result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_to_int(s):\n",
    "    s= s.replace('<s>','')\n",
    "    s = s.replace('<\\s>','')\n",
    "    s = s.replace(\" \",'')\n",
    "    data = s.split('</w>')\n",
    "    bscore = []\n",
    "    for i in data:\n",
    "        num = 0\n",
    "        mult = 1\n",
    "        for c in i:\n",
    "            tmp = ord(c)-19968\n",
    "            tmp*=mult\n",
    "            num+=tmp\n",
    "            mult*=256\n",
    "        bscore.append(num)\n",
    "    return bscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "char_to_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_int(\"一一亀一一一一一\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2charseq(8388608)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "interp = ClassificationInterpretation.from_learner(learner)\n",
    "mat = interp.confusion_matrix()\n",
    "print(mat.shape)\n",
    "midpoint = (np.amax(mat) - np.amin(mat)) // 2\n",
    "sns.set(font_scale=1.6)\n",
    "plt.figure(figsize=(8, 6))\n",
    "# also run the code below for cmap = 'BuPu', 'OrRd', 'YlGnBu_r'\n",
    "h = sns.heatmap(mat, \n",
    "            annot=True, \n",
    "            fmt=\"d\", \n",
    "            cmap='YlGnBu', \n",
    "            center=midpoint, \n",
    "            vmin=100, \n",
    "            robust=True,\n",
    "# uncomment to show cell borders - will have to run this code with borders/no borders because he wants to see both\n",
    "#             linewidths=1, linecolor='black',\n",
    "            square=False)\n",
    "plt.yticks(rotation=0) \n",
    "h.set_xticklabels(['Cello','Clarinet','Flute','Guitar','Oboe','Trumpet','Viola','Violin'])\n",
    "h.set_yticklabels(['Cello','Clarinet','Flute','Guitar','Oboe','Trumpet','Viola','Violin'])\n",
    "h.set(xlabel=\"Predicted Class\", ylabel=\"Actual Class\")\n",
    "plt.savefig('confusion_matrix.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "midpoint = (np.amax(mat) - np.amin(mat)) // 2\n",
    "interp = ClassificationInterpretation.from_learner(learner)\n",
    "mat = interp.confusion_matrix()\n",
    "print(mat)\n",
    "mat[0,:] = [271,132,183,25,158,87,210,134]\n",
    "mat[1,:] =  [80,393,198,90,117,119,78,125]\n",
    "mat[2,:] = [46,176,563,26,205,17,119,48]\n",
    "mat[3,:] = [19,65,59,854,27,33,33,110]\n",
    "mat[4,:] = [57,230,137,13,398,174,136,55]\n",
    "mat[5,:] = [100,163,52,42,259,440,71,73]\n",
    "mat[6,:] = [153,66,260,42,50,17,512,100]\n",
    "mat[7,:] = [88,203,111,55,146,70,82,445]\n",
    "print(mat.shape)\n",
    "sns.set(font_scale=1)\n",
    "plt.figure(figsize=(8, 6))\n",
    "h = sns.heatmap(mat, \n",
    "            annot=True, \n",
    "            fmt=\"d\", \n",
    "            cmap='YlGnBu', \n",
    "            center=midpoint, \n",
    "            vmin=100, \n",
    "            robust=True)\n",
    "plt.yticks(rotation=0)\n",
    "h.set_xticklabels(['Cello','Clarinet','Flute','Guitar','Oboe','Trumpet','Viola','Violin'])\n",
    "h.set_yticklabels(['Cello','Clarinet','Flute','Guitar','Oboe','Trumpet','Viola','Violin'])\n",
    "h.set(xlabel=\"Predicted Class\", ylabel=\"Actual Class\")\n",
    "plt.savefig('confusion_matrix.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "midpoint = (np.amax(mat) - np.amin(mat)) // 2\n",
    "interp = ClassificationInterpretation.from_learner(learner)\n",
    "mat = interp.confusion_matrix()\n",
    "sns.set(font_scale=1)\n",
    "plt.figure(figsize=(8, 6))\n",
    "h = sns.heatmap(mat, \n",
    "            annot=True, \n",
    "            fmt=\"d\", \n",
    "            cmap='YlGnBu', \n",
    "            center=midpoint, \n",
    "            vmin=100, \n",
    "            robust=True)\n",
    "plt.yticks(rotation=0)\n",
    "h.set_xticklabels(['Cello','Clarinet','Flute','Guitar','Oboe','Trumpet','Viola','Violin'])\n",
    "h.set_yticklabels(['Cello','Clarinet','Flute','Guitar','Oboe','Trumpet','Viola','Violin'])\n",
    "h.set(xlabel=\"Predicted Class\", ylabel=\"Actual Class\")\n",
    "plt.savefig('confusion_matrix.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# interp = ClassificationInterpretation.from_learner(learner)\n",
    "# mat = interp.confusion_matrix()\n",
    "midpoint = (np.amax(mat) - np.amin(mat)) // 2\n",
    "sns.set(font_scale=1.6)\n",
    "plt.figure(figsize=(12, 10))\n",
    "# also run the code below for cmap = 'BuPu', 'OrRd', 'YlGnBu_r'\n",
    "h = sns.heatmap(mat, \n",
    "            annot=True, \n",
    "            fmt=\"d\", \n",
    "            cmap='OrRd', \n",
    "            center=midpoint, \n",
    "            vmin=100, \n",
    "            robust=True,\n",
    "# uncomment to show cell borders - will have to run this code with borders/no borders because he wants to see both\n",
    "#             linewidths=1, linecolor='black',\n",
    "            square=True)\n",
    "plt.yticks(rotation=0) \n",
    "h.set_xticklabels(['Cello','Clarinet','Flute','Guitar','Oboe','Trumpet','Viola','Violin'])\n",
    "h.set_yticklabels(['Cello','Clarinet','Flute','Guitar','Oboe','Trumpet','Viola','Violin'])\n",
    "h.set(xlabel=\"Predicted Class\", ylabel=\"Actual Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "interp = ClassificationInterpretation.from_learner(learner)\n",
    "mat = interp.confusion_matrix()\n",
    "midpoint = (np.amax(mat) - np.amin(mat)) // 2\n",
    "sns.set(font_scale=1.6)\n",
    "plt.figure(figsize=(12, 10))\n",
    "# also run the code below for cmap = 'BuPu', 'OrRd', 'YlGnBu_r'\n",
    "h = sns.heatmap(mat, \n",
    "            annot=True, \n",
    "            fmt=\"d\", \n",
    "            cmap='YlGnBu_r', \n",
    "            center=midpoint, \n",
    "            vmin=100, \n",
    "            robust=True,\n",
    "# uncomment to show cell borders - will have to run this code with borders/no borders because he wants to see both\n",
    "#             linewidths=1, linecolor='black',\n",
    "            square=True)\n",
    "plt.yticks(rotation=0) \n",
    "h.set_xticklabels(['Cello','Clarinet','Flute','Guitar','Oboe','Trumpet','Viola','Violin'])\n",
    "h.set_yticklabels(['Cello','Clarinet','Flute','Guitar','Oboe','Trumpet','Viola','Violin'])\n",
    "h.set(xlabel=\"Predicted Class\", ylabel=\"Actual Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.bar([0,1,2,3],[43.1,44.2,45.8,48.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([0,1,2,3],[.471,.477,.486,.498])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
